{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization as ML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea es que vamos a  buscar una función que depende de $\\Theta$ (conjunto de todos los parámetros) de la forma $J(\\Theta)$ que se conoce como función objetivo. De esta forma, estamos interesados en buscar un $$\\Theta^*\\equiv argmin{J(\\Theta)}$$\n",
    "Se pueden escribir infinits funciones objetivas, no onstante, es muy fácil utilizar una función de pérdida $\\mathcal{L}$, es decir que podemos escribir:\n",
    "\n",
    "$$J(\\Theta)=\\frac{1}{n}\\sum_{i=1}^{n}\\mathcal{l}(h(x^{(i)};\\Theta),y^{(i)})+\\lambda R(\\Theta)$$\n",
    "\n",
    "Donde $R(\\Theta)$ se le conoce como $\\textbf{Regularizador}$ para evitar el overfitting, $\\lambda$ es un hiperparámetro positivo de dicta que tan compleja debería ser la hipótesis $h(x^{(i)};\\Theta)$.\n",
    "\n",
    "Una vez tenemos esta función con una hipótesis, se pueden desarrollar $\\textit{algos}$ que permitan optimizarla para encontrar el $\\Theta^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Logistic Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se les conoce como $\\textbf{Logistic Regression}$ que nos permite establecer un nuevo tipo de función de pérdida y de funciones de clase. La función de predicción toma la forma:\n",
    "\n",
    "$$LLC(x;\\theta,\\theta_0)=\\sigma(\\theta^Tx+\\theta_0)$$\n",
    "\n",
    "Para esto debemos recordar la función sigmoide:\n",
    "\n",
    "$$\\sigma(z)=\\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "A este valor que arroja $\\sigma(z) \\in (0,1)$ le podemos interpretar como la posibilidad de que $z$ sea positivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta forma, si queremos un clasificador, tenemos que poner un límite en esta función, por ejemplo la más simple puede ser \n",
    "$$\\sigma(\\theta^Tx+\\theta_0)\\ge 0.5\\iff \\theta^Tx+\\theta_0\\ge0$$.\n",
    "$$ $$\n",
    "Procedemos entonces a definir las funciones de pérdida y regularizador.\n",
    "* La función de pérdida está relacionada inversamente con la probabilidad de que $\\Theta$ de cuenta de los datos, para ello hacemos las siguientes definiciones:\n",
    "$$g^{(i)}\\equiv\\sigma(\\theta^Tx^{(i)}+\\theta_0)$$\n",
    "De esta forma definimos una función de pérdida logarítmica de la forma\n",
    "$$\\mathcal{L}_{nll}=-\\sum _{i = 1}^ n \\left( {y^{(i)}}\\log {g^{(i)}} + (1 - y^{(i)})\\log (1 - g^{(i)})\\right)\\; \\; $$\n",
    "\n",
    "$$\\mathcal{L}_\\text {nll}(\\text {guess},\\text {actual}) = -\\left(\\text {actual}\\cdot \\log (\\text {guess}) + (1 - \\text {actual})\\cdot \\log (1 - \\text {guess})\\right) \\; \\; $$\n",
    "\n",
    "* Una forma sencilla de establecer un estabilizador que evite el overfitting es: \n",
    "$$R(\\theta)=||\\Theta-\\Theta_{prior}||\\equiv||\\theta||$$\n",
    "$$\\;$$\n",
    "\n",
    "Ya tenemos casi todo listo, nos falta buscar una forma sencilla pero útil de hacer una optimización con los datos y la función de pérdida, para esto vamos a introducir:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es por mucho uno de los algoritmos más eficientes y rápidos de entender para realizar optimización, vamos entonces a analizarlo:\n",
    "* $\\textbf{Una dimensión:}$\n",
    "Partimos de un valor de $\\theta$, Vamos a ir calculando derivadas y a ir haciendo pequeños pasos en dirección opuesta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradDesUniDim(th,f,derivf,epsi,eta,t_max=1000):\n",
    "    \"\"\"\"Pasar f como función lambda\"\"\"\n",
    "    ths=[th];ban=True;t=0\n",
    "    while ban:\n",
    "        t+=1\n",
    "        ths.append(ths[t-1]-eta*derif(ths[t-1]))\n",
    "        if (f(ths[t])-f(ths[t-1]))<epsi or t>=t_max: ban=False\n",
    "    return ths[t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\textbf{Múltiples dimesiones:}$ Salimos con una función que tiene $m$ argumentos, es decir que $\\theta$  es de tamaño $m\\times 1$ y supongamos que $f(\\Theta)$ es una función escalar. También se necesitan $\\nabla_{\\theta} f$ y una primera aproximación para $\\theta$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(f, df, x0, step_size_fn, max_iter):\n",
    "    prev_x = x0\n",
    "    fs = []; xs = []\n",
    "    for i in range(max_iter):\n",
    "        prev_f, prev_grad = f(prev_x), df(prev_x)\n",
    "        fs.append(prev_f); xs.append(prev_x)\n",
    "        if i == max_iter-1:\n",
    "            return prev_x, fs, xs\n",
    "        step = step_size_fn(i)\n",
    "        prev_x = prev_x - step * prev_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar la función de gradiente numérico, si $x$ es un vector columna con los parámetros de la función escalar $f$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_grad(f, delta=0.001):\n",
    "    def df(x):\n",
    "        g = np.zeros(x.shape)\n",
    "        for i in range(x.shape[0]):\n",
    "            xi = x[i,0]\n",
    "            x[i,0] = xi - delta\n",
    "            fxm = f(x)\n",
    "            x[i,0] = xi + delta\n",
    "            fxp = f(x)\n",
    "            x[i,0] = xi\n",
    "            g[i,0] = (fxp - fxm)/(2*delta)\n",
    "        return g\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces una función que minimice completamente es:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize(f, x0, step_size_fn, max_iter):\n",
    "    df = num_grad(f)\n",
    "    return gd(f, df, x0, step_size_fn, max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otra Función de Pérdida: Linear Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe una forma un poco más eficiente de tomar las funciónes de pérdida con respecto a una $\\gamma$ de referencia, a esta función se le llama Hingle Loss:\n",
    "$$L_{H}\\left( \\gamma ,\\gamma _{ref}\\right) =\\begin{cases}1-\\left( \\dfrac{\\gamma}{\\gamma_{ref}}\\right) ;\\gamma  <\\gamma _{ref}\\\\\n",
    "0;otro \\end{cases}$$\n",
    "\n",
    "De esta forma, en resumen podemos concluir que por SMV la función objetivo de la optimización es : \n",
    "\n",
    "$$J(\\theta,\\theta_0)=\\frac{1}{n}\\sum_{i=1}^{n}L_H\\big(y^{(i)}\\cdot(\\theta x^{(i)}+\\theta_0)\\big)+\\lambda ||\\theta||^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de $gd$ a SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta implementación, $x$ es $d\\times n$, $y$ es $1\\times n$, $th$ es $1\\times 1$ y $lam$ es un escalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge(v):\n",
    "    return np.where(v >= 1, 0, 1 - v)\n",
    "\n",
    "def hinge_loss(x, y, th, th0):\n",
    "    return hinge(y * (np.dot(th.T, x) + th0))\n",
    "\n",
    "def svm_obj(X, y, th, th0, lam):\n",
    "    return np.mean(hinge_loss(X, y, th, th0)) + lam * np.linalg.norm(th) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_hinge(v):\n",
    "    return np.where(v >= 1, 0, -1)\n",
    "def d_hinge_loss_th(x, y, th, th0):\n",
    "    return d_hinge(y*(np.dot(th.T, x) + th0))* y * x\n",
    "def d_hinge_loss_th0(x, y, th, th0):\n",
    "    return d_hinge(y*(np.dot(th.T, x) + th0)) * y\n",
    "def d_svm_obj_th(x, y, th, th0, lam):\n",
    "    return np.mean(d_hinge_loss_th(x, y, th, th0), axis = 1, keepdims = True) + lam * 2 * th\n",
    "def d_svm_obj_th0(x, y, th, th0, lam):\n",
    "    return np.mean(d_hinge_loss_th0(x, y, th, th0), axis = 1, keepdims = True)\n",
    "def svm_obj_grad(X, y, th, th0, lam):\n",
    "    grad_th = d_svm_obj_th(X, y, th, th0, lam)\n",
    "    grad_th0 = d_svm_obj_th0(X, y, th, th0, lam)\n",
    "    return np.vstack([grad_th, grad_th0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_svm_min(data, labels, lam):\n",
    "    def svm_min_step_size_fn(i):\n",
    "       return 2/(i+1)**0.5\n",
    "    init = np.zeros((data.shape[0] + 1, 1))\n",
    "\n",
    "    def f(th):\n",
    "      return svm_obj(data, labels, th[:-1, :], th[-1:,:], lam)\n",
    "\n",
    "    def df(th):\n",
    "      return svm_obj_grad(data, labels, th[:-1, :], th[-1:,:], lam)\n",
    "\n",
    "    x, fs, xs = gd(f, df, init, svm_min_step_size_fn, 10)\n",
    "    return x, fs, xs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
