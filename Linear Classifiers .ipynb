{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo más sencillo de Perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x is dimension d by 1\n",
    "# th is dimension d by 1\n",
    "# th0 is dimension 1 by 1\n",
    "# return 1 by 1 matrix of +1, 0, -1\n",
    "def positive(x, th, th0):\n",
    "   return np.sign(th.T@x + th0)\n",
    "\n",
    "\n",
    "# Perceptron algorithm with offset.\n",
    "# data is dimension d by n\n",
    "# labels is dimension 1 by n\n",
    "# T is a positive integer number of steps to run\n",
    "def perceptron(data, labels, params = {}, hook = None):\n",
    "    # if T not in params, default to 100\n",
    "    T = params.get('T', 100)\n",
    "    (d, n) = data.shape\n",
    "\n",
    "    theta = np.zeros((d, 1)); theta_0 = np.zeros((1, 1))\n",
    "    for t in range(T):\n",
    "        for i in range(n):\n",
    "            x = data[:,i:i+1]\n",
    "            y = labels[:,i:i+1]\n",
    "            if y * positive(x, theta, theta_0) <= 0.0:\n",
    "                theta = theta + y * x\n",
    "                theta_0 = theta_0 + y\n",
    "                if hook: hook((theta, theta_0))\n",
    "    return theta, theta_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos hacerlo pasar por el origen de coordenadas siempre.\n",
    "Para que se pueda utilizar, el dataset D debe ser linealmente separable a través del origen, es decir:$\\exists \\theta$ tal que\n",
    "\n",
    "$ y^{(i)}(\\theta^T x^{(i)}\\geq 0)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el $\\textbf{margin}$ de un data point $(x,y)$ como:$$y\\cdot \\frac{\\theta^Tx}{||\\theta ||}$$ Esto resulta ser unamuy buena medida de qué tan bien estamos (debería ser positivo si le atinamos). Y si estamos hablamos de un dataset, es el $i$ que tenga margin mínimo.$$$$\n",
    "\n",
    "Con esto se establece el $\\textbf{Perceptron Convergence Theorem}$: Si:\n",
    "* $ \\exists \\theta^* | y^{(i)}\\cdot \\frac{\\theta^{T*}x}{||\\theta^* ||}\\geq \\gamma$               $ \\forall i $\n",
    ": Donde $\\theta^*$ es el margin de $\\theta^*$ en el data set\n",
    "* $||x^{(i)}||\\leq R$\n",
    ": Es decir, los valores negativos se pueden encerrar en un circulo de radio real\n",
    "\n",
    "\n",
    "Entonces el Perceptron va a tener máximo $\\big(\\frac{R}{\\gamma}\\big)^2$ errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para una solución más estable se puede utilizar el $\\textbf{averaged perceptron}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x is dimension d by 1\n",
    "# th is dimension d by 1\n",
    "# th0 is dimension 1 by 1\n",
    "# return 1 by 1 matrix of +1, 0, -1\n",
    "def positive(x, th, th0):\n",
    "   return np.sign(th.T@x + th0)\n",
    "\n",
    "def averaged_perceptron(data, labels, params = {}, hook = None):\n",
    "    T = params.get('T', 100)\n",
    "    (d, n) = data.shape\n",
    "\n",
    "    theta = np.zeros((d, 1)); theta_0 = np.zeros((1, 1))\n",
    "    theta_sum = theta.copy() \n",
    "    theta_0_sum = theta_0.copy()\n",
    "    for t in range(T):\n",
    "        for i in range(n):\n",
    "            x = data[:,i:i+1]\n",
    "            y = labels[:,i:i+1]\n",
    "            if y * positive(x, theta, theta_0) <= 0.0:\n",
    "                theta = theta + y * x\n",
    "                theta_0 = theta_0 + y\n",
    "                if hook: hook((theta, theta_0))\n",
    "            theta_sum = theta_sum + theta\n",
    "            theta_0_sum = theta_0_sum + theta_0\n",
    "    theta_avg = theta_sum / (T*n)\n",
    "    theta_0_avg = theta_0_sum / (T*n)\n",
    "    if hook: hook((theta_avg, theta_0_avg))\n",
    "    return theta_avg, theta_0_avg\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estrategias de Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Captura de pantalla de 2021-01-02 14-12-38\n",
    "\n",
    "\n",
    "def eval_classifier(learner, data_train, labels_train, data_test, labels_test):\n",
    "    th, th0 = learner(data_train, labels_train)\n",
    "    return score(data_test, labels_test, th, th0)/data_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Toma un algoritmo de aprendizaje y una fuente de datos como entrada y ejecuta el algoritmo de aprendizaje varias veces, cada vez evaluando el clasificador resultante como se indicó anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_learning_alg(learner, data_gen, n_train, n_test, it):\n",
    "    score_sum = 0\n",
    "    for i in range(it):\n",
    "        data_train, labels_train = data_gen(n_train)\n",
    "        data_test, labels_test = data_gen(n_test)\n",
    "        score_sum += eval_classifier(learner, data_train, labels_train,\n",
    "                                              data_test, labels_test)\n",
    "    return score_sum/it      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La validación cruzada es una estrategia para evaluar un algoritmo de aprendizaje, utilizando un único conjunto de entrenamiento de tamaño $n$. La validación cruzada incluye un algoritmo de aprendizaje $L$, un conjunto de datos fijo $\\mathcal {D}$ y un parámetro $k$. Ejecutará el algoritmo de aprendizaje $k$ veces diferentes, luego evaluará la precisión del clasificador resultante y, en última instancia, devolverá el promedio de las precisiones sobre cada una de las $k$ \"corridas\" de $L$. Está estructurado así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xval_learning_alg(learner, data, labels, k):\n",
    "    s_data = np.array_split(data, k, axis=1)\n",
    "    s_labels = np.array_split(labels, k, axis=1)\n",
    "\n",
    "    score_sum = 0\n",
    "    for i in range(k):\n",
    "        data_train = np.concatenate(s_data[:i] + s_data[i+1:], axis=1)\n",
    "        labels_train = np.concatenate(s_labels[:i] + s_labels[i+1:], axis=1)\n",
    "        data_test = np.array(s_data[i])\n",
    "        labels_test = np.array(s_labels[i])\n",
    "        score_sum += eval_classifier(learner, data_train, labels_train,\n",
    "                                              data_test, labels_test)\n",
    "    return score_sum/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
